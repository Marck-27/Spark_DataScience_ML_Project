{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning con la librería MLlib  de Spark\n",
    "\n",
    "En el presente script construiremos una red neuronal para clasificación múltiple\n",
    "\n",
    "Todos los procesos serán coleccionados en un Pipeline explícito \n",
    "\n",
    "* No mostramos la salida de los Stages del Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import * #<-- importa todos los tipos de dato como: StringType, FloatType DoubleType, DateType, etc.\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import udf, StringType\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('deep_learning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.76:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>deep_learning</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f840a086b20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./data/Iris_data/Iris.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos variables para trabajar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas que no usaremos:\n",
    "unused_cols = ['Id'] #<-- vacío si usaremos todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columnas que usaremos:\n",
    "selected_cols = [ c for c in data.columns if c not in unused_cols ]\n",
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+-------------+------------+-------------+------------+-----------+\n",
      "|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.select( selected_cols )\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SepalLengthCm: string (nullable = true)\n",
      " |-- SepalWidthCm: string (nullable = true)\n",
      " |-- PetalLengthCm: string (nullable = true)\n",
      " |-- PetalWidthCm: string (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustamos tipos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Species']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos nombres de columnas categóricas:\n",
    "categ_cols = ['Species']#[item[0] for item in data.dtypes if item[1].startswith('string')]\n",
    "categ_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A las columnas categóricas les asignamos el tipo \"String\"\n",
    "# A las columnas numéricas les asignamos el tipo \"Double\"\n",
    "\n",
    "for col in data.columns:    \n",
    "    if col in categ_cols:\n",
    "        # Asignamos el tipo \"String\"\n",
    "        data = data.withColumn( col , data[col].cast( StringType() ) )\n",
    "    else:\n",
    "        # Asignamos el tipo \"Double\"\n",
    "        data = data.withColumn( col , data[col].cast( DoubleType() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SepalLengthCm: double (nullable = true)\n",
      " |-- SepalWidthCm: double (nullable = true)\n",
      " |-- PetalLengthCm: double (nullable = true)\n",
      " |-- PetalWidthCm: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificamos columnas numéricas y categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = data.dtypes\n",
    "numerical_columns = [ item[0] for item in data.dtypes if item[1] != 'string' ]\n",
    "categoric_columns = [ item[0] for item in data.dtypes if item[1].startswith('string') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas: \n",
      " ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "\n",
      "Columnas categóricas: \n",
      " ['Species']\n"
     ]
    }
   ],
   "source": [
    "print('Columnas numéricas: \\n', numerical_columns)\n",
    "print('\\nColumnas categóricas: \\n', categoric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajamos con campos nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0              0             0              0             0        0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "\n",
    "# Mostramos el número de campos vacíos en cada columna:\n",
    "df_nulls = data.select([count(when(isnull(c), True)).alias(c) for c in data.columns]).toPandas()\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos algunos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport\n",
    "\n",
    "#df_pandas = data.toPandas()\n",
    "\n",
    "#pfr = ProfileReport(df_pandas)\n",
    "#pfr.to_notebook_iframe()\n",
    "#pfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraemos las clases de datos que hay en cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0             35            23             43            22        3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos el número de clases de datos en cada columna\n",
    "from pyspark.sql.functions import countDistinct, col\n",
    "\n",
    "data.select( [ countDistinct( col(c) ).alias(c) for c in data.columns ] ).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificamos la columna de labels y las columnas de features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Species\n",
       "0   Iris-virginica\n",
       "1      Iris-setosa\n",
       "2  Iris-versicolor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col = \"Species\" #\"x_3\" # <-- nombre de la columna que usaremos como labels\n",
    "\n",
    "# Obtenemos las clases de valores de la columna de labels:\n",
    "classes = data.select([ label_col ]).distinct().toPandas()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de clases de salida:\n",
    "n_class_out = len( classes )\n",
    "n_class_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columnas que formaran los features:\n",
    "feature_cols = [col for col in selected_cols if col != label_col]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into Train, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test  = data.randomSplit([0.7, 0.2, 0.1], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+-------------+------------+-------------+------------+-----------+\n",
      "|          4.4|         3.0|          1.3|         0.2|Iris-setosa|\n",
      "|          4.4|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|          4.6|         3.2|          1.4|         0.2|Iris-setosa|\n",
      "|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
      "+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicia creación de Pipeline\n",
    "\n",
    "Antes de llegar a este paso debemos tener el dataset limpio y listo para trabajar.\n",
    "\n",
    "Estaremos usando la función `StringIndexer` que asigna un valor entero a cada categoría de datos, iniciando forzosamente dede 0.\n",
    "\n",
    "0 se asigna a la categoría más frecuente, 1 a la siguiente categoría más frecuente y así sucesivamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Creación de columna de labels codificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringIndexer_11f67d3ac934"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stage_1 = StringIndexer(inputCol = label_col, outputCol = \"labels\")\n",
    "Stage_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Transformación de features categóricos a numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos nombres de columnas categóricas que formaran los features (ie. no incluyen el label):\n",
    "categoric_cols_features = [ c for c in categoric_columns if c != label_col ]\n",
    "categoric_cols_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nombres de nuevas columnas numéricas que formaran los features:\n",
    "categoric_cols_features_num = [ c+'_num' for c in categoric_cols_features]\n",
    "categoric_cols_features_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos nuevas columnas numéricas para los features:\n",
    "Stage_2 = []\n",
    "for i in range( len(categoric_cols_features) ):    \n",
    "    st_i = StringIndexer(inputCol = categoric_cols_features[i] , outputCol = categoric_cols_features_num[i] , handleInvalid='keep')\n",
    "    Stage_2.append(st_i)\n",
    "\n",
    "Stage_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Creación de columna de vectores de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos columnas numéricas para los features:\n",
    "numeric_cols_features = [col for col in numerical_columns if col != label_col]\n",
    "numeric_cols_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coleccionamos todas las columnas numericas que formaran a los features:\n",
    "required_features = numeric_cols_features + categoric_cols_features_num\n",
    "required_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_473d7abbd748"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stage_3 = VectorAssembler(inputCols=required_features, outputCol='features')\n",
    "Stage_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4: Creación de columna de vectores de features reescalados (entre 0 y 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler_23a36ce26ff6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reescalamos los features para tomen valore entre 0 y 1:\n",
    "Stage_4 = MinMaxScaler(min=0.0, max=1.0, inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "Stage_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 5: Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamaño (dimensión) de cada feature:\n",
    "dim_xi = len( required_features )\n",
    "dim_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 3]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos el número de neuronas en cada capa de la red:\n",
    "layers = [ dim_xi, 2, n_class_out]\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch_size\n",
    "batch_size = round( 0.15*train.count()  )# 128\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultilayerPerceptronClassifier_a58cfd7067b7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declaramos el clasificador: \n",
    "Stage_5 = MultilayerPerceptronClassifier(\n",
    "    labelCol='labels', \n",
    "    featuresCol='scaled_features', \n",
    "    maxIter=200, \n",
    "    layers=layers, \n",
    "    blockSize=batch_size, \n",
    "    seed=1234,\n",
    "    stepSize=0.05,\n",
    "    solver='l-bfgs'\n",
    "    )\n",
    "    \n",
    "Stage_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_11f67d3ac934,\n",
       " VectorAssembler_473d7abbd748,\n",
       " MinMaxScaler_23a36ce26ff6,\n",
       " MultilayerPerceptronClassifier_a58cfd7067b7]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coleccionamos todos los Satges en una lista:\n",
    "Stages_list = [Stage_1] + Stage_2 + [ Stage_3, Stage_4, Stage_5]\n",
    "Stages_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_ada19e020024"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = Stages_list )\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_de54e83ba00d"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecutamos el pipeline y se entrena el modelo con los datos de entrenamiento:\n",
    "\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "model # <-- Contiene el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecimos datos de entrenamiento, validación y pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_show = ['labels', 'scaled_features', 'rawPrediction','probability','prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|labels|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|   1.0|[0.0,0.4761904761...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.0,0.5714285714...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.05714285714285...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.05714285714285...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.05714285714285...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de entrenamiento:\n",
    "train_prediction = model.transform(train)\n",
    "train_prediction.select(cols_to_show).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|labels|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|   1.0|[-0.0285714285714...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.0,0.4285714285...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.02857142857142...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.14285714285714...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.17142857142857...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de validación:\n",
    "val_prediction = model.transform(validation)\n",
    "val_prediction.select(cols_to_show).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|labels|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|   1.0|[0.17142857142857...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.17142857142857...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   1.0|[0.31428571428571...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|   0.0|[0.34285714285714...|[21.8418883945205...|[0.97142856271924...|       0.0|\n",
      "|   1.0|[0.37142857142857...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de pruebas:\n",
    "test_prediction = model.transform(test)\n",
    "test_prediction.select(cols_to_show).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas 'label' y 'prediction' de los DataFrames predichos:\n",
    "train_Labels_Prediction = train_prediction.select('labels','prediction')\n",
    "validation_Labels_Prediction = val_prediction.select('labels','prediction')\n",
    "test_Labels_Prediction = test_prediction.select('labels','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores de metrica << weightedPrecision >>\n",
      "Train =  0.9901875901875902\n",
      "Validation =  0.9752252252252253\n",
      "Test =  0.8979591836734693\n",
      "\n",
      "Valores de metrica << weightedRecall >>\n",
      "Train =  0.9898989898989898\n",
      "Validation =  0.972972972972973\n",
      "Test =  0.8571428571428572\n",
      "\n",
      "Valores de metrica << accuracy >>\n",
      "Train =  0.98989898989899\n",
      "Validation =  0.972972972972973\n",
      "Test =  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Elegimos las siguientes métricas:\n",
    "metrics = ['weightedPrecision', 'weightedRecall', 'accuracy']\n",
    "\n",
    "# Obtenemos los valores de cada métrica, aplicadas a los datos de entrenamiento, validación y pruebas:\n",
    "for metric in metrics:\n",
    "    # Declaramos la métrica actual:\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol='labels', predictionCol='prediction', metricName=metric)\n",
    "    \n",
    "    f_train = evaluator.evaluate( train_Labels_Prediction )\n",
    "    f_validation = evaluator.evaluate( validation_Labels_Prediction )\n",
    "    f_test = evaluator.evaluate( test_Labels_Prediction )\n",
    "\n",
    "    print('\\nValores de metrica << ' + metric ,'>>' )\n",
    "    print('Train = ' , f_train)\n",
    "    print('Validation = ' , f_validation)\n",
    "    print('Test = ' , f_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ejecutó:  rm -r ./Models_trained/pipeline_model_Iris\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import system\n",
    "\n",
    "path = './Models_trained/pipeline_model_Iris'\n",
    "\n",
    "# En caso de que exista la ruta la borramos para volver a crearla:\n",
    "if os.path.exists( path ):\n",
    "    # Comando a ejecutar:\n",
    "    comando = 'rm -r ' + path\n",
    "    # Ejecutamos el comando:\n",
    "    system( comando )\n",
    "    print('Se ejecutó: ',comando)\n",
    "\n",
    "\n",
    "# Guardamos el modelo entrenado:\n",
    "model.save( path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el modelo entrenado y hacemos una predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo:\n",
    "#from pyspark.ml.classification import MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "modelo_NN = PipelineModel.load( path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+---------------+------+-----------------+--------------------+--------------------+--------------------+----------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|        Species|labels|         features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+-------------+------------+-------------+------------+---------------+------+-----------------+--------------------+--------------------+--------------------+----------+\n",
      "|          5.0|         3.0|          1.6|         0.2|    Iris-setosa|   1.0|[5.0,3.0,1.6,0.2]|[0.17142857142857...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|          5.0|         3.3|          1.4|         0.2|    Iris-setosa|   1.0|[5.0,3.3,1.4,0.2]|[0.17142857142857...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|          5.5|         3.5|          1.3|         0.2|    Iris-setosa|   1.0|[5.5,3.5,1.3,0.2]|[0.31428571428571...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "|          5.6|         3.0|          4.1|         1.3|Iris-versicolor|   0.0|[5.6,3.0,4.1,1.3]|[0.34285714285714...|[21.8418883945205...|[0.97142856271924...|       0.0|\n",
      "|          5.7|         3.8|          1.7|         0.3|    Iris-setosa|   1.0|[5.7,3.8,1.7,0.3]|[0.37142857142857...|[-60.976831522981...|[8.49815870494266...|       1.0|\n",
      "+-------------+------------+-------------+------------+---------------+------+-----------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de pruebas:\n",
    "predictions_test = modelo_NN.transform(test)\n",
    "predictions_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculamos la precisión manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión en las predicciones de los datos de prueba es del 86 %\n"
     ]
    }
   ],
   "source": [
    "wrong_test = predictions_test.filter( predictions_test['labels']!=predictions_test['prediction'] ).count()\n",
    "right_test = predictions_test.filter( predictions_test['labels']==predictions_test['prediction'] ).count()\n",
    "\n",
    "acc_test =  right_test/(right_test + wrong_test)\n",
    "\n",
    "print( 'La precisión en las predicciones de los datos de prueba es del',round(acc_test * 100),'%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta de predicciones individuales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos mapeo de labels:\n",
    "\n",
    "Crearemos el DataFrame de pandas `labels_map` que contiene la relación entre los labels del dataset original y los labels reescalados que se usaron para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------+------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|labels|\n",
      "+-------------+------------+-------------+------------+-----------+------+\n",
      "|          5.1|         3.5|          1.4|         0.2|Iris-setosa|   0.0|\n",
      "|          4.9|         3.0|          1.4|         0.2|Iris-setosa|   0.0|\n",
      "|          4.7|         3.2|          1.3|         0.2|Iris-setosa|   0.0|\n",
      "|          4.6|         3.1|          1.5|         0.2|Iris-setosa|   0.0|\n",
      "|          5.0|         3.6|          1.4|         0.2|Iris-setosa|   0.0|\n",
      "+-------------+------------+-------------+------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Scaler_labels = Stage_1.fit(data)\n",
    "data_transform = Scaler_labels.transform(data)\n",
    "data_transform.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels          Species\n",
       "0     0.0      Iris-setosa\n",
       "2     1.0  Iris-versicolor\n",
       "1     2.0   Iris-virginica"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos el mapeo entre la columna de labels reales y labels reescalados:\n",
    "labels_map = data_transform.select( [label_col , 'labels'] ).groupBy( [label_col,'labels'] ).count().toPandas()\n",
    "labels_map = labels_map.sort_values('labels')\n",
    "\n",
    "# Mapeo de labels:\n",
    "labels_map[['labels', label_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función que asigna el nombre del label original al label codificado:\n",
    "def f_map_label(x):\n",
    "    for i in range( len(labels_map) ):\n",
    "        if x == labels_map['labels'][i]:\n",
    "            y = labels_map[label_col][i]\n",
    "    return y\n",
    "\n",
    "# Declaramos la función como UDF de Spark:\n",
    "f_map_label_udf = udf( lambda x: f_map_label(x) )#, StringType() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamamos a las componentes de features que necesitamos para generar una predicción:\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|\n",
      "+-------------+------------+-------------+------------+\n",
      "|          5.5|         3.5|          1.3|         0.2|\n",
      "|          5.6|         3.0|          4.1|         1.3|\n",
      "+-------------+------------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingresamos features manualmente:\n",
    "datos = [ \n",
    "    (5.5, 3.5, 1.3, 0.2), #<-- Registro 1\n",
    "    (5.6, 3.0, 4.1, 1.3)  #<-- Registro 2\n",
    "    ] \n",
    "\n",
    "sample_df = spark.createDataFrame(datos, feature_cols)\n",
    "\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------------+--------------------+--------------------+--------------------+----------+---------------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|         features|     scaled_features|       rawPrediction|         probability|prediction|prediction_true|\n",
      "+-------------+------------+-------------+------------+-----------------+--------------------+--------------------+--------------------+----------+---------------+\n",
      "|          5.5|         3.5|          1.3|         0.2|[5.5,3.5,1.3,0.2]|[0.31428571428571...|[-60.976831522981...|[8.49815870494266...|       1.0|Iris-versicolor|\n",
      "|          5.6|         3.0|          4.1|         1.3|[5.6,3.0,4.1,1.3]|[0.34285714285714...|[21.8418883945205...|[0.97142856271924...|       0.0|    Iris-setosa|\n",
      "+-------------+------------+-------------+------------+-----------------+--------------------+--------------------+--------------------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data_test = modelo_NN.transform(sample_df)\n",
    "sample_data_test = sample_data_test.withColumn('prediction_true', f_map_label_udf(\"prediction\"))\n",
    "sample_data_test.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerramos sesión Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
