{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning con la librería MLlib  de Spark\n",
    "\n",
    "En el presente script construiremos una red neuronal para clasificación binaria\n",
    "\n",
    "Todos los procesos serán coleccionados en un Pipeline explícito "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import * #<-- importa todos los tipos de dato como: StringType, FloatType DoubleType, DateType, etc.\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import udf, StringType\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('deep_learning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.76:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>deep_learning</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe6f496db20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./data/Titanic/titanic-train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male| 22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female| 26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male| 35|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos variables para trabajar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas que no usaremos:\n",
    "unused_cols = ['PassengerId','Name','SibSp','Parch','Ticket','Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columnas que usaremos:\n",
    "selected_cols = [ c for c in data.columns if c not in unused_cols ]\n",
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+---+-------+--------+\n",
      "|Survived|Pclass|   Sex|Age|   Fare|Embarked|\n",
      "+--------+------+------+---+-------+--------+\n",
      "|       0|     3|  male| 22|   7.25|       S|\n",
      "|       1|     1|female| 38|71.2833|       C|\n",
      "|       1|     3|female| 26|  7.925|       S|\n",
      "|       1|     1|female| 35|   53.1|       S|\n",
      "|       0|     3|  male| 35|   8.05|       S|\n",
      "+--------+------+------+---+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.select( selected_cols )\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustamos tipos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas categóricas:\n",
    "categ_cols = ['Sex','Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A las columnas categóricas les asignamos el tipo \"String\"\n",
    "# A las columnas numéricas les asignamos el tipo \"Double\"\n",
    "\n",
    "for col in data.columns:    \n",
    "    if col in categ_cols:\n",
    "        # Asignamos el tipo \"String\"\n",
    "        data = data.withColumn( col , data[col].cast( StringType() ) )\n",
    "    else:\n",
    "        # Asignamos el tipo \"Double\"\n",
    "        data = data.withColumn( col , data[col].cast( DoubleType() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: double (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificamos columnas numéricas y categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = data.dtypes\n",
    "numerical_columns = [ item[0] for item in data.dtypes if item[1] != 'string' ]\n",
    "categoric_columns = [ item[0] for item in data.dtypes if item[1].startswith('string') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas: \n",
      " ['Survived', 'Pclass', 'Age', 'Fare']\n",
      "\n",
      "Columnas categóric: \n",
      " ['Sex', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print('Columnas numéricas: \\n', numerical_columns)\n",
    "print('\\nColumnas categóric: \\n', categoric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajamos con campos nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Fare  Embarked\n",
       "0         0       0    0  177     0         2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "\n",
    "# Mostramos el número de campos vacíos en cada columna:\n",
    "df_nulls = data.select([count(when(isnull(c), True)).alias(c) for c in data.columns]).toPandas()\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos la edad promedio:\n",
    "mu_age = data.agg( {\"Age\": \"avg\"} ).collect()[0][0]\n",
    "mu_age = round(mu_age)\n",
    "mu_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos las edades faltantes con el promedio:\n",
    "data = data.fillna( mu_age, [\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Fare  Embarked\n",
       "0         0       0    0    0     0         2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el número de campos vacíos en cada columna:\n",
    "df_nulls = data.select([count(when(isnull(c), True)).alias(c) for c in data.columns]).toPandas()\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos el resto de filas con algún campo vacío:\n",
    "\n",
    "#data.filter( data['Embarked'].isNull() ).show()\n",
    "\n",
    "data = data.replace('null', None)\\\n",
    "    .dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Fare  Embarked\n",
       "0         0       0    0    0     0         0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el número de campos vacíos en cada columna:\n",
    "df_nulls = data.select([count(when(isnull(c), True)).alias(c) for c in data.columns]).toPandas()\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for c in df_nulls.columns:\n",
    "    # Extraemos el valor de la celda:\n",
    "    n_nulls = df_nulls[c][0]\n",
    "    if ( n_nulls > 0):\n",
    "        print('Error!!! La columna',c,'tiene',n_nulls,'campos nulos' )\n",
    "        stop()\n",
    "    else:\n",
    "        print('No se encontraron campos nulos en la columna:',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos algunos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport\n",
    "\n",
    "#df_pandas = data.toPandas()\n",
    "\n",
    "#pfr = ProfileReport(df_pandas)\n",
    "#pfr.to_notebook_iframe()\n",
    "#pfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraemos las clases de datos que hay en cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Fare  Embarked\n",
       "0         2       3    2   88   247         3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos el número de clases de datos en cada columna\n",
    "\n",
    "from pyspark.sql.functions import countDistinct, col\n",
    "\n",
    "data.select( [ countDistinct( col(c) ).alias(c) for c in data.columns ] ).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificamos la columna de labels y las columnas de features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0       0.0\n",
       "1       1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col = \"Survived\"#Pclass\" # <-- nombre de la columna que usaremos como labels\n",
    "\n",
    "# Obtenemos las clases de valores de la columna de labels:\n",
    "classes = data.select([ label_col ]).distinct().toPandas()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de clases de salida:\n",
    "n_class_out = len( classes )\n",
    "n_class_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columnas que formaran los features:\n",
    "feature_cols = [col for col in selected_cols if col != label_col]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into Train, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test  = data.randomSplit([0.7, 0.2, 0.1], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+--------+--------+\n",
      "|Survived|Pclass|   Sex| Age|    Fare|Embarked|\n",
      "+--------+------+------+----+--------+--------+\n",
      "|     0.0|   1.0|female|50.0| 28.7125|       C|\n",
      "|     0.0|   1.0|  male|18.0|   108.9|       C|\n",
      "|     0.0|   1.0|  male|19.0|   263.0|       S|\n",
      "|     0.0|   1.0|  male|21.0| 77.2875|       S|\n",
      "|     0.0|   1.0|  male|22.0|135.6333|       C|\n",
      "+--------+------+------+----+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicia creación de Pipeline\n",
    "\n",
    "Antes de llegar a este paso debemos tener el dataset limpio y listo para trabajar.\n",
    "\n",
    "Estaremos usando la función `StringIndexer` que asigna un valor entero a cada categoría de datos, iniciando forzosamente dede 0.\n",
    "\n",
    "0 se asigna a la categoría más frecuente, 1 a la siguiente categoría más frecuente y así sucesivamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Creación de columna de labels codificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringIndexer_a4c536c1b212"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stage_1 = StringIndexer(inputCol = label_col, outputCol = \"labels\")\n",
    "Stage_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+--------+--------+------+\n",
      "|Survived|Pclass|   Sex| Age|    Fare|Embarked|labels|\n",
      "+--------+------+------+----+--------+--------+------+\n",
      "|     0.0|   1.0|female|50.0| 28.7125|       C|   0.0|\n",
      "|     0.0|   1.0|  male|18.0|   108.9|       C|   0.0|\n",
      "|     0.0|   1.0|  male|19.0|   263.0|       S|   0.0|\n",
      "|     0.0|   1.0|  male|21.0| 77.2875|       S|   0.0|\n",
      "|     0.0|   1.0|  male|22.0|135.6333|       C|   0.0|\n",
      "+--------+------+------+----+--------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver la salida del stage \n",
    "Scaler_1 = Stage_1.fit(train)\n",
    "data_transform = Scaler_1.transform(train)\n",
    "data_transform.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Transformación de features categóricos a numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Embarked']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos nombres de columnas categóricas que formaran los features (ie. no incluyen el label):\n",
    "categoric_cols_features = [ c for c in categoric_columns if c != label_col ]\n",
    "categoric_cols_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_num', 'Embarked_num']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nombres de nuevas columnas numéricas que formaran los features:\n",
    "categoric_cols_features_num = [ c+'_num' for c in categoric_cols_features]\n",
    "categoric_cols_features_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_093bacfc53ae, StringIndexer_90727a54632f]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos nuevas columnas numéricas para los features:\n",
    "Stage_2 = []\n",
    "for i in range( len(categoric_cols_features) ):    \n",
    "    st_i = StringIndexer(inputCol = categoric_cols_features[i] , outputCol = categoric_cols_features_num[i] , handleInvalid='keep')\n",
    "    Stage_2.append(st_i)\n",
    "\n",
    "Stage_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+--------+--------+------+-------+------------+\n",
      "|Survived|Pclass|   Sex| Age|    Fare|Embarked|labels|Sex_num|Embarked_num|\n",
      "+--------+------+------+----+--------+--------+------+-------+------------+\n",
      "|     0.0|   1.0|female|50.0| 28.7125|       C|   0.0|    1.0|         1.0|\n",
      "|     0.0|   1.0|  male|18.0|   108.9|       C|   0.0|    0.0|         1.0|\n",
      "|     0.0|   1.0|  male|19.0|   263.0|       S|   0.0|    0.0|         0.0|\n",
      "|     0.0|   1.0|  male|21.0| 77.2875|       S|   0.0|    0.0|         0.0|\n",
      "|     0.0|   1.0|  male|22.0|135.6333|       C|   0.0|    0.0|         1.0|\n",
      "+--------+------+------+----+--------+--------+------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver la salida del stage \n",
    "for st in Stage_2:\n",
    "    Scaler_i = st.fit(data_transform)\n",
    "    data_transform = Scaler_i.transform(data_transform)\n",
    "    \n",
    "data_transform.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Creación de columna de vectores de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Age', 'Fare']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos columnas numéricas para los features:\n",
    "numeric_cols_features = [col for col in numerical_columns if col != label_col]\n",
    "numeric_cols_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Age', 'Fare', 'Sex_num', 'Embarked_num']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coleccionamos todas las columnas numericas que formaran a los features:\n",
    "required_features = numeric_cols_features + categoric_cols_features_num\n",
    "required_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_388ca11e2e7a"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stage_3 = VectorAssembler(inputCols=required_features, outputCol='features')\n",
    "Stage_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+--------+--------+------+-------+------------+--------------------+\n",
      "|Survived|Pclass|   Sex| Age|    Fare|Embarked|labels|Sex_num|Embarked_num|            features|\n",
      "+--------+------+------+----+--------+--------+------+-------+------------+--------------------+\n",
      "|     0.0|   1.0|female|50.0| 28.7125|       C|   0.0|    1.0|         1.0|[1.0,50.0,28.7125...|\n",
      "|     0.0|   1.0|  male|18.0|   108.9|       C|   0.0|    0.0|         1.0|[1.0,18.0,108.9,0...|\n",
      "|     0.0|   1.0|  male|19.0|   263.0|       S|   0.0|    0.0|         0.0|[1.0,19.0,263.0,0...|\n",
      "|     0.0|   1.0|  male|21.0| 77.2875|       S|   0.0|    0.0|         0.0|[1.0,21.0,77.2875...|\n",
      "|     0.0|   1.0|  male|22.0|135.6333|       C|   0.0|    0.0|         1.0|[1.0,22.0,135.633...|\n",
      "+--------+------+------+----+--------+--------+------+-------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver la salida del stage \n",
    "data_transform = Stage_3.transform(data_transform)\n",
    "data_transform.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4: Creación de columna de vectores de features reescalados (entre 0 y 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler_cbca689a9b07"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reescalamos los features para tomen valore entre 0 y 1:\n",
    "Stage_4 = MinMaxScaler(min=0.0, max=1.0, inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "Stage_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+--------+--------+------+-------+------------+--------------------+--------------------+\n",
      "|Survived|Pclass|   Sex| Age|    Fare|Embarked|labels|Sex_num|Embarked_num|            features|     scaled_features|\n",
      "+--------+------+------+----+--------+--------+------+-------+------------+--------------------+--------------------+\n",
      "|     0.0|   1.0|female|50.0| 28.7125|       C|   0.0|    1.0|         1.0|[1.0,50.0,28.7125...|[0.0,0.7024652876...|\n",
      "|     0.0|   1.0|  male|18.0|   108.9|       C|   0.0|    0.0|         1.0|[1.0,18.0,108.9,0...|[0.0,0.2490790592...|\n",
      "|     0.0|   1.0|  male|19.0|   263.0|       S|   0.0|    0.0|         0.0|[1.0,19.0,263.0,0...|(5,[1,2],[0.26324...|\n",
      "|     0.0|   1.0|  male|21.0| 77.2875|       S|   0.0|    0.0|         0.0|[1.0,21.0,77.2875...|(5,[1,2],[0.29158...|\n",
      "|     0.0|   1.0|  male|22.0|135.6333|       C|   0.0|    0.0|         1.0|[1.0,22.0,135.633...|[0.0,0.3057523377...|\n",
      "+--------+------+------+----+--------+--------+------+-------+------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------------------+----------------------------------------------------+\n",
      "|features                   |scaled_features                                     |\n",
      "+---------------------------+----------------------------------------------------+\n",
      "|[1.0,50.0,28.7125,1.0,1.0] |[0.0,0.7024652876168886,0.05604306762136532,1.0,0.5]|\n",
      "|[1.0,18.0,108.9,0.0,1.0]   |[0.0,0.24907905922357607,0.2125586439344078,0.0,0.5]|\n",
      "|[1.0,19.0,263.0,0.0,0.0]   |(5,[1,2],[0.2632473788608671,0.5133418122566507])   |\n",
      "|[1.0,21.0,77.2875,0.0,0.0] |(5,[1,2],[0.2915840181354491,0.15085515328815924])  |\n",
      "|[1.0,22.0,135.6333,0.0,1.0]|[0.0,0.30575233777274013,0.2647385704347907,0.0,0.5]|\n",
      "+---------------------------+----------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver la salida del stage:\n",
    "Scaler_4 = Stage_4.fit(data_transform)\n",
    "data_transform = Scaler_4.transform(data_transform)\n",
    "data_transform.show(5)\n",
    "data_transform.select(['features','scaled_features']).show(5,truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: double (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- labels: double (nullable = false)\n",
      " |-- Sex_num: double (nullable = false)\n",
      " |-- Embarked_num: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_transform.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 5: Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamaño (dimensión) de cada feature:\n",
    "dim_xi = len( required_features )\n",
    "dim_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos el número de neuronas en cada capa de la red:\n",
    "layers = [ dim_xi, 5, 5, n_class_out]\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch_size\n",
    "batch_size = round( 0.15*train.count()  )# 128\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultilayerPerceptronClassifier_6dddc2cb6e14"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declaramos el clasificador: \n",
    "Stage_5 = MultilayerPerceptronClassifier(\n",
    "    labelCol='labels', \n",
    "    featuresCol='scaled_features', \n",
    "    maxIter=200, \n",
    "    layers=layers, \n",
    "    blockSize=batch_size, \n",
    "    seed=1234,\n",
    "    stepSize=0.05,\n",
    "    solver='l-bfgs'\n",
    "    )\n",
    "    \n",
    "Stage_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_a4c536c1b212,\n",
       " StringIndexer_093bacfc53ae,\n",
       " StringIndexer_90727a54632f,\n",
       " VectorAssembler_388ca11e2e7a,\n",
       " MinMaxScaler_cbca689a9b07,\n",
       " MultilayerPerceptronClassifier_6dddc2cb6e14]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coleccionamos todos los Satges en una lista:\n",
    "Stages_list = [Stage_1] + Stage_2 + [ Stage_3, Stage_4, Stage_5]\n",
    "Stages_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_e7266506cca3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = Stages_list )\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_fb98a2071692"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecutamos el pipeline y se entrena el modelo con los datos de entrenamiento:\n",
    "\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "model # <-- Contiene el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecimos datos de entrenamiento, validación y pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_show = ['labels', 'scaled_features', 'rawPrediction','probability','prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|labels|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|   0.0|[0.0,0.7024652876...|[-1.2715959028706...|[0.04430370027271...|       1.0|\n",
      "|   0.0|[0.0,0.2490790592...|[1.86795249796720...|[0.95673286969995...|       0.0|\n",
      "|   0.0|(5,[1,2],[0.26324...|[0.23040625291253...|[0.35866716413488...|       1.0|\n",
      "|   0.0|(5,[1,2],[0.29158...|[0.62974284876193...|[0.57535994347029...|       0.0|\n",
      "|   0.0|[0.0,0.3057523377...|[1.67707397768485...|[0.93616344085321...|       0.0|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de entrenamiento:\n",
    "train_prediction = model.transform(train)\n",
    "train_prediction.select(cols_to_show).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|labels|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|   0.0|[0.0,0.0223859450...|[-1.2715952392302...|[0.04430375702653...|       1.0|\n",
      "|   0.0|[0.0,0.3482572966...|[-1.2715949324516...|[0.04430378301155...|       1.0|\n",
      "|   0.0|(5,[1,2],[0.26324...|[0.62945696199511...|[0.57520515273816...|       0.0|\n",
      "|   0.0|[0.0,0.4190988948...|[0.74347336384405...|[0.66418433825797...|       0.0|\n",
      "|   0.0|(5,[1,2],[0.41909...|[0.64188521977737...|[0.58192036309823...|       0.0|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de validación:\n",
    "val_prediction = model.transform(validation)\n",
    "val_prediction.select(cols_to_show).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|labels|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "|   0.0|(5,[1,2],[0.41909...|[0.64200935066894...|[0.58198728526648...|       0.0|\n",
      "|   0.0|[0.0,0.4190988948...|[0.63006357110512...|[0.60792728094507...|       0.0|\n",
      "|   0.0|(5,[1,2],[0.70246...|[1.16673398507296...|[0.80235148122640...|       0.0|\n",
      "|   0.0|(5,[1,2],[0.77330...|[1.39641032121019...|[0.86415211494170...|       0.0|\n",
      "|   0.0|(5,[1,2],[0.87248...|[1.45317415771221...|[0.87666129299990...|       0.0|\n",
      "+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de pruebas:\n",
    "test_prediction = model.transform(test)\n",
    "test_prediction.select(cols_to_show).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas 'label' y 'prediction' de los DataFrames predichos:\n",
    "train_Labels_Prediction = train_prediction.select('labels','prediction')\n",
    "validation_Labels_Prediction = val_prediction.select('labels','prediction')\n",
    "test_Labels_Prediction = test_prediction.select('labels','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores de metrica << weightedPrecision >>\n",
      "Train =  0.8395786161973068\n",
      "Validation =  0.766638391582725\n",
      "Test =  0.7830459770114943\n",
      "\n",
      "Valores de metrica << weightedRecall >>\n",
      "Train =  0.8405103668261563\n",
      "Validation =  0.7657142857142858\n",
      "Test =  0.7816091954022988\n",
      "\n",
      "Valores de metrica << accuracy >>\n",
      "Train =  0.8405103668261563\n",
      "Validation =  0.7657142857142857\n",
      "Test =  0.7816091954022989\n"
     ]
    }
   ],
   "source": [
    "# Elegimos las siguientes métricas:\n",
    "metrics = ['weightedPrecision', 'weightedRecall', 'accuracy']\n",
    "\n",
    "# Obtenemos los valores de cada métrica, aplicadas a los datos de entrenamiento, validación y pruebas:\n",
    "for metric in metrics:\n",
    "    # Declaramos la métrica actual:\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol='labels', predictionCol='prediction', metricName=metric)\n",
    "    \n",
    "    f_train = evaluator.evaluate( train_Labels_Prediction )\n",
    "    f_validation = evaluator.evaluate( validation_Labels_Prediction )\n",
    "    f_test = evaluator.evaluate( test_Labels_Prediction )\n",
    "\n",
    "    print('\\nValores de metrica << ' + metric ,'>>' )\n",
    "    print('Train = ' , f_train)\n",
    "    print('Validation = ' , f_validation)\n",
    "    print('Test = ' , f_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ejecutó:  rm -r ./Models_trained/pipeline_model_Titanic\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import system\n",
    "\n",
    "path = './Models_trained/pipeline_model_Titanic'\n",
    "\n",
    "# En caso de que exista la ruta la borramos para volver a crearla:\n",
    "if os.path.exists( path ):\n",
    "    # Comando a ejecutar:\n",
    "    comando = 'rm -r ' + path\n",
    "    # Ejecutamos el comando:\n",
    "    system( comando )\n",
    "    print('Se ejecutó: ',comando)\n",
    "\n",
    "\n",
    "# Guardamos el modelo entrenado:\n",
    "model.save( path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el modelo entrenado y hacemos una predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo:\n",
    "#from pyspark.ml.classification import MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "modelo_NN = PipelineModel.load( path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-----+--------+------+-------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass| Sex| Age| Fare|Embarked|labels|Sex_num|Embarked_num|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+----+----+-----+--------+------+-------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|   1.0|male|30.0| 31.0|       S|   0.0|    0.0|         0.0|[1.0,30.0,31.0,0....|(5,[1,2],[0.41909...|[0.64200935066894...|[0.58198728526648...|       0.0|\n",
      "|     0.0|   1.0|male|30.0| 39.6|       C|   0.0|    0.0|         1.0|[1.0,30.0,39.6,0....|[0.0,0.4190988948...|[0.63006357110512...|[0.60792728094507...|       0.0|\n",
      "|     0.0|   1.0|male|50.0| 55.9|       S|   0.0|    0.0|         0.0|[1.0,50.0,55.9,0....|(5,[1,2],[0.70246...|[1.16673398507296...|[0.80235148122640...|       0.0|\n",
      "|     0.0|   1.0|male|55.0| 30.5|       S|   0.0|    0.0|         0.0|[1.0,55.0,30.5,0....|(5,[1,2],[0.77330...|[1.39641032121019...|[0.86415211494170...|       0.0|\n",
      "|     0.0|   1.0|male|62.0|26.55|       S|   0.0|    0.0|         0.0|[1.0,62.0,26.55,0...|(5,[1,2],[0.87248...|[1.45317415771221...|[0.87666129299990...|       0.0|\n",
      "+--------+------+----+----+-----+--------+------+-------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos datos de pruebas:\n",
    "predictions_test = modelo_NN.transform(test)\n",
    "predictions_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculamos la precisión manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión en las predicciones de los datos de prueba es del 78 %\n"
     ]
    }
   ],
   "source": [
    "wrong_test = predictions_test.filter( predictions_test['labels']!=predictions_test['prediction'] ).count()\n",
    "right_test = predictions_test.filter( predictions_test['labels']==predictions_test['prediction'] ).count()\n",
    "\n",
    "acc_test =  right_test/(right_test + wrong_test)\n",
    "\n",
    "print( 'La precisión en las predicciones de los datos de prueba es del',round(acc_test * 100),'%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta de predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos mapeo de labels:\n",
    "\n",
    "Crearemos el DataFrame de pandas `labels_map` que contiene la relación entre los labels del dataset original y los labels reescalados que se usaron para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+--------+--------+------+\n",
      "|Survived|Pclass|   Sex| Age|    Fare|Embarked|labels|\n",
      "+--------+------+------+----+--------+--------+------+\n",
      "|     0.0|   1.0|female|50.0| 28.7125|       C|   0.0|\n",
      "|     0.0|   1.0|  male|18.0|   108.9|       C|   0.0|\n",
      "|     0.0|   1.0|  male|19.0|   263.0|       S|   0.0|\n",
      "|     0.0|   1.0|  male|21.0| 77.2875|       S|   0.0|\n",
      "|     0.0|   1.0|  male|22.0|135.6333|       C|   0.0|\n",
      "+--------+------+------+----+--------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Scaler_labels = Stage_1.fit(train)\n",
    "data_transform = Scaler_labels.transform(train)\n",
    "data_transform.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels  Survived\n",
       "1     0.0       0.0\n",
       "0     1.0       1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos el mapeo entre la columna de labels reales y labels reescalados:\n",
    "labels_map = data_transform.select( [label_col , 'labels'] ).groupBy( [label_col,'labels'] ).count().toPandas()\n",
    "labels_map = labels_map.sort_values('labels')\n",
    "\n",
    "# Mapeo de labels:\n",
    "labels_map[['labels', label_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamamos a las componentes de features que necesitamos\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+------+--------+\n",
      "|Pclass|   Sex|Age|  Fare|Embarked|\n",
      "+------+------+---+------+--------+\n",
      "|   3.0|  male| 25|  25.2|       C|\n",
      "|   1.0|female| 75|135.65|       S|\n",
      "+------+------+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingresamos features manualmente:\n",
    "datos = [ \n",
    "    (3.0 , 'male',   25 , 25.2 , 'C'), #<-- Registro 1\n",
    "    (1.0 , 'female', 75 , 135.65, 'S')  #<-- Registro 2\n",
    "    ] \n",
    "\n",
    "sample_df = spark.createDataFrame(datos, feature_cols)\n",
    "\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+------+--------+-------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Pclass|   Sex|Age|  Fare|Embarked|Sex_num|Embarked_num|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+------+------+---+------+--------+-------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|   3.0|  male| 25|  25.2|       C|    0.0|         1.0|[3.0,25.0,25.2,0....|[1.0,0.3482572966...|[0.54100060600374...|[0.52565914735767...|       0.0|\n",
      "|   1.0|female| 75|135.65|       S|    1.0|         0.0|[1.0,75.0,135.65,...|[0.0,1.0566732785...|[-0.9932989713211...|[0.07429082882438...|       1.0|\n",
      "+------+------+---+------+--------+-------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data_test = modelo_NN.transform(sample_df)\n",
    "sample_data_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerramos sesión Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
